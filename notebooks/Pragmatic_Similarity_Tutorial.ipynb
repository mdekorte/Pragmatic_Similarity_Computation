{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72145f2-5e65-4eaa-9bf9-4b6329ec243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook can be used to run the pragmatic similarity metric (https://www.cs.utep.edu/nigel/papers/similarity-kos.pdf) on the DRAL dataset (https://www.cs.utep.edu/nigel/papers/interspeech2023.pdf & https://www.cs.utep.edu/nigel/papers/dral-techreport2.pdf).\n",
    "# The objective of this metric is to find sentences with similar pragmatic intent in the dataset, even when the textual content is quite different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08d9966-bef5-44fa-8753-ce67c75fed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -r ../requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46b37c-48de-432c-96a1-3cda4d8b8877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Add parent directory to Python path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import cosine_similarity as cs\n",
    "import feature_extractor as fe\n",
    "import feature_selection as fs\n",
    "import similarity_finder as sf\n",
    "\n",
    "similarity_finder = sf.SimilarityFinder(feature_selection=True, directory_path=os.path.dirname(os.getcwd()), clips_for_comparison_path='data/dral_en.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36c62cf-dd6a-466b-9789-f8e452c36c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain DRAL data and put in the right place\n",
    "# Running this cell is optional, since features for the English DRAL corpus are already extracted in data/dral_en.csv\n",
    "\n",
    "import os, tarfile, shutil, requests\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Paths\n",
    "data_dir = \"../data\"\n",
    "dral_dir = os.path.join(data_dir, \"dral\")\n",
    "target_check = os.path.join(dral_dir, \"fragments-short\")\n",
    "url = \"https://www.cs.utep.edu/nigel/dral/DRAL-16kHz.tgz\"\n",
    "tgz_path = os.path.join(data_dir, \"DRAL-16kHz.tgz\")\n",
    "\n",
    "if not os.path.exists(target_check):\n",
    "    os.makedirs(dral_dir, exist_ok=True)\n",
    "\n",
    "    print(\"Downloading DRAL dataset...\")\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        total_size = int(r.headers.get('content-length', 0))\n",
    "        block_size = 1024 * 1024\n",
    "        with open(tgz_path, 'wb') as f, tqdm(\n",
    "            total=total_size, unit='B', unit_scale=True, desc=\"Downloading\"\n",
    "        ) as pbar:\n",
    "            for chunk in r.iter_content(chunk_size=block_size):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    pbar.update(len(chunk))\n",
    "\n",
    "    print(\"Extracting selected folders...\")\n",
    "    with tarfile.open(tgz_path, \"r:gz\") as tar:\n",
    "        wanted = {\"fragments-short\", \"metadata\"}\n",
    "        members = [\n",
    "            m for m in tar.getmembers()\n",
    "            if m.name.startswith(\"DRAL16kHz/\")\n",
    "            and len(m.name.split(\"/\")) > 1\n",
    "            and m.name.split(\"/\")[1] in wanted\n",
    "        ]\n",
    "        tar.extractall(path=data_dir, members=members)\n",
    "\n",
    "    # Move wanted folders into data/dral/\n",
    "    extracted_root = os.path.join(data_dir, \"DRAL16kHz\")\n",
    "    for folder in wanted:\n",
    "        src = os.path.join(extracted_root, folder)\n",
    "        dst = os.path.join(dral_dir, folder)\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "    # Cleanup\n",
    "    os.remove(tgz_path)\n",
    "    shutil.rmtree(extracted_root, ignore_errors=True)\n",
    "\n",
    "    print(\"DRAL data ready in:\", os.path.abspath(dral_dir))\n",
    "else:\n",
    "    print(\"DRAL data already present at:\", os.path.abspath(dral_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff945fb-52d6-47bd-aaba-e8b03f0b95d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to make a call to find similar clips and record its overlap\n",
    "recently_updated_clips = []\n",
    "\n",
    "def find_similar_clips(id, path):\n",
    "    global recently_updated_clips\n",
    "    first_place, second_place, third_place, thousandth_place, fifteen_hundredth_place, last_place = \\\n",
    "        similarity_finder.find_similar(path)\n",
    "    clip = {'id': id,\n",
    "            'path': path,\n",
    "            'best_path': first_place[1],\n",
    "            'best_cos': round(first_place[0].item(), 2),\n",
    "            'second_path': second_place[1],\n",
    "            'second_cos': round(second_place[0].item(), 2),\n",
    "            'third_path': third_place[1],\n",
    "            'third_cos': round(third_place[0].item(), 2),            \n",
    "            'thousandth_path': thousandth_place[1],\n",
    "            'thousandth_cos': round(thousandth_place[0].item(), 2),\n",
    "            'fifteen_hundredth_path': fifteen_hundredth_place[1],\n",
    "            'fifteen_hundredth_cos': round(fifteen_hundredth_place[0].item(), 2),\n",
    "            'worst_path': last_place[1],\n",
    "            'worst_cos': round(last_place[0].item(), 2)\n",
    "            }\n",
    "    print(f\"\\n{clip}\\n\")\n",
    "    recently_updated_clips.append(clip)\n",
    "    return clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f7dd83-ec45-41f1-bc75-85077e2b6117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make your own recording for comparison: record a 5 second audio fragment yourself and have it compared with the dataset.\n",
    "# likely, the cosine similarity will not be too high because of the difference between monologue recordings and dialogue speech.\n",
    "\n",
    "import sounddevice as sd\n",
    "from datetime import datetime \n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def record_audio():\n",
    "    fs = 16000\n",
    "    seconds = 5\n",
    "    \n",
    "    print(\"Recording...\")\n",
    "    myrecording = sd.rec(int(seconds * fs), samplerate=fs, channels=1)\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    \n",
    "    recording_name = f\"recording_{datetime.now():%Y%m%d_%H%M%S}.wav\"\n",
    "    recording_path = os.path.join(os.path.dirname(os.getcwd()), \"clips\", recording_name)\n",
    "    write(recording_path, fs, myrecording)\n",
    "    print(\"Saved recording\") \n",
    "    return recording_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8525af-de5e-434a-8a4b-e25e8fc40b7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sim_eval_option = \"choose_existing_clip\" # Choose from \"record_audio\", \"choose_existing_clip\", \"choose_specific_dataset_clip\", \"choose_random_dataset_clip\"\n",
    "dataset_loc = \"data/dral/fragments-short\"\n",
    "\n",
    "# \"choose_specific_dataset_clip\" and \"choose_random_dataset_clip\" requires dataset download\n",
    "if sim_eval_option == \"record_audio\":\n",
    "    audio_path = record_audio()\n",
    "elif sim_eval_option == \"choose_existing_clip\": # assumes audio file stored in clips dir\n",
    "    audio_filename = \"LJ025-0076.wav\" # a random LJ Speech sample that is out of distribution (read speech rather than dialogue speech)\n",
    "    audio_path = os.path.join(os.path.dirname(os.getcwd()), \"clips\", audio_filename)\n",
    "elif sim_eval_option == \"choose_specific_dataset_clip\": \n",
    "    audio_filename = \"EN_001_19.wav\" # provide name of specific file in DRAL dataset\n",
    "    audio_path = os.path.join(os.path.dirname(os.getcwd()), dataset_loc, audio_filename)\n",
    "elif sim_eval_option == \"choose_random_dataset_clip\":\n",
    "    audio_folder = os.path.join(os.path.dirname(os.getcwd()), dataset_loc)\n",
    "    prefix = \"EN_\" if similarity_finder.language.lower() == \"english\" else \"ES_\"\n",
    "    files = [f for f in os.listdir(audio_folder) if f.startswith(prefix) and f.endswith((\".wav\", \".mp3\"))]\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No {prefix}-files found in {audio_folder}\")\n",
    "    audio_path = os.path.join(audio_folder, random.choice(files))\n",
    "else:\n",
    "    raise NotImplementedError(\"This evaluation option is not implemented\")\n",
    "\n",
    "clip = find_similar_clips(0, audio_path) # ARGS: audio_id and audio_path. Possible to add multiple or create for loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d73a2d-218e-4b03-9333-262303ad4e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# play selected clips one by one, with a pause of a second in between\n",
    "similarity_finder.play_clip(clip['path'])\n",
    "similarity_finder.play_clip(clip['best_path'])\n",
    "similarity_finder.play_clip(clip['second_path'])\n",
    "similarity_finder.play_clip(clip['third_path'])\n",
    "similarity_finder.play_clip(clip['thousandth_path'])\n",
    "similarity_finder.play_clip(clip['fifteen_hundredth_path'])\n",
    "similarity_finder.play_clip(clip['worst_path'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
